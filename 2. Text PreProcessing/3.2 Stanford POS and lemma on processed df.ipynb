{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook we perform lemmatization using  NLTK library and we use standford coreNLP part of speech tagger**\n",
    "* A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.\n",
    "* Unlike stemming Lemmatisation considers meaning of  the word in a sentence, and reduces it to a word that present in dictionary/vocabulary .\n",
    "* Example: Good, better, best are lemmatized to word  good since they have same meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\me\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# necessary import for POS n lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford POS tagger importing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_path = \"C:/Program Files/Java/jdk1.8.0_201/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "#os.environ['STANFORD_POSTAGGER'] = \"C:/Users/Me/Documents/stanford-postagger-full-2018-10-16\"\n",
    "os.environ['STANFORD_POSTAGGER'] = \"C:/Users/Me/Desktop/ppr red/Library file/stanford-postagger-full-2018-10-16\"\n",
    "english_postagger = StanfordPOSTagger(os.environ['STANFORD_POSTAGGER'] +'/models/english-bidirectional-distsim.tagger',os.environ['STANFORD_POSTAGGER']+'/stanford-postagger.jar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_pickle(\"./pickles/preProcessed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absolutely wonderful silk sex comfortable</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love dress 's soon pretty happened find store ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high hopes dress really wanted work initially ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating  Recommended IND\n",
       "0          absolutely wonderful silk sex comfortable       4                1\n",
       "1  love dress 's soon pretty happened find store ...       5                1\n",
       "2  high hopes dress really wanted work initially ...       3                0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ought black go larkspur mid dress n't bother lining skirt portion grrrrrrrrrrr states a-28/29-36 fit smoothly around chest flow around lower half would say 's running big straps pretty could easily nightwear 'm 5'6 '' came knees\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Review Text\"].iloc[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stanford POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ought', 'MD'), ('black', 'JJ'), ('go', 'NN'), ('larkspur', 'NN'), ('mid', 'JJ'), ('dress', 'NN'), (\"n't\", 'RB'), ('bother', 'VB'), ('lining', 'JJ'), ('skirt', 'NN'), ('portion', 'NN'), ('grrrrrrrrrrr', 'NN'), ('states', 'VBZ'), ('a-28/29-36', 'JJ'), ('fit', 'NN'), ('smoothly', 'RB'), ('around', 'IN'), ('chest', 'NN'), ('flow', 'NN'), ('around', 'IN'), ('lower', 'JJR'), ('half', 'NN'), ('would', 'MD'), ('say', 'VB'), (\"'s\", 'POS'), ('running', 'VBG'), ('big', 'JJ'), ('straps', 'NNS'), ('pretty', 'RB'), ('could', 'MD'), ('easily', 'RB'), ('nightwear', 'RB'), (\"'m\", 'VB'), (\"5'6\", 'JJ'), ('``', '``'), ('came', 'VBD'), ('knees', 'NNS')]\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "tagged = english_postagger.tag(word_tokenize(df[\"Review Text\"].iloc[13]))\n",
    "print(tagged)\n",
    "print(len(tagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting POS tags so that lemmatizer recognises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to convert the tag from the pos_tagger to one of the four \"syntactic categories\" that wordnet recognizes,\n",
    "# then pass that to the lemmatizer as the word_pos.\n",
    "# so lemmatizer can process it\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None # for easy if-statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_lemma(tag):\n",
    "    for word, tag in tagged:\n",
    "        \n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        \n",
    "        if wntag is None:# not supply tag in case of None\n",
    "            lemma = nltk_lemmatizer.lemmatize(word)\n",
    "            #return \"\".join(lemma)\n",
    "            print(lemma)\n",
    "        else:\n",
    "            lemma = nltk_lemmatizer.lemmatize(word, pos=wntag)\n",
    "            #return \"\".join(lemma)\n",
    "            print(lemma)\n",
    "# to return it as lst create new lst and append to it\n",
    "# later \" \".join(row_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ought\n",
      "black\n",
      "go\n",
      "larkspur\n",
      "mid\n",
      "dress\n",
      "n't\n",
      "bother\n",
      "lining\n",
      "skirt\n",
      "portion\n",
      "grrrrrrrrrrr\n",
      "state\n",
      "a-28/29-36\n",
      "fit\n",
      "smoothly\n",
      "around\n",
      "chest\n",
      "flow\n",
      "around\n",
      "low\n",
      "half\n",
      "would\n",
      "say\n",
      "'s\n",
      "run\n",
      "big\n",
      "strap\n",
      "pretty\n",
      "could\n",
      "easily\n",
      "nightwear\n",
      "'m\n",
      "5'6\n",
      "``\n",
      "come\n",
      "knee\n",
      "None\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(nltk_lemma(tagged))\n",
    "print(len(tagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* you can even try it out with spacy, textblob or other algo.\n",
    "* currently handled for only 4 part of speech types \n",
    "* Unlike stemming we saw in previous notebook, lemmatizer reduces it to actual word in english dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
