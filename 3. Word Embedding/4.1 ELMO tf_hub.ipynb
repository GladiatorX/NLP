{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handling missing word in embedding\n",
    "* I think the best solution to this problem is to use a language model that is able to generate embedding vectors even when it does not know the exact word. This is the case with fasttext and ELMO embeddings / models.\n",
    "\n",
    "\n",
    "**authors train a charCNN + bi-LSTM language model then use the internal representations from this model to produce \"ELMo\" representations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53798582/is-elmo-a-word-embedding-or-a-sentence-embedding\n",
    "\n",
    "The output dictionary contains:\n",
    "\n",
    "word_emb: the character-based word representations with shape [batch_size, max_length, 512].\n",
    "\n",
    "lstm_outputs1: the first LSTM hidden state with shape [batch_size, max_length, 1024].\n",
    "\n",
    "lstm_outputs2: the second LSTM hidden state with shape [batch_size, max_length, 1024].\n",
    "\n",
    "elmo: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape [batch_size, max_length, 1024]\n",
    "\n",
    "default: a fixed mean-pooling of all contextualized word representations with shape [batch_size, 1024].\n",
    "\n",
    "**The 4th layer is the actual word embedding. The 5th one reduces sequence output by the 4th layer to a single vector, effectively turning the whole thing into a sentence embedding.**\n",
    "\n",
    "How can I train my own ELMo embeddings on my own data for later use in the model?\n",
    "* -sadly this cannot be done with the tensorflow hub model directly. You have to train the bilm model they used in the paper and convert it to a tensorhub model yourself. Here you can find the code to train the bilm https://github.com/allenai/bilm-tf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting neccesary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  importing elmo thats downloaded locally\n",
    "* original_file.tar.gz converted using 7 zip \n",
    " \n",
    "* https://tfhub.dev/google/elmo/2 **Reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"D:/dataset/Embedding/tf_module_ELMO2\", trainable=False) # trinable = True / False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING [elmo]\n",
    "**elmo: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape [batch_size, max_length, 1024]**\n",
    "* has actual word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Passing Sentences as ip\n",
    "**signature=\"default\"**\n",
    "* word_emb: the character-based word representations with shape [batch_size, max_length, 512]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without seq len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "                        #6                     #5                     #5\n",
    "sentence_embeddings = elmo([\"the cat is on the mat \", \"dogs are in the fog\",\"I am hungry want food\"],\n",
    "                  signature=\"default\",\n",
    "                  as_dict=True)[\"elmo\"]\n",
    "\n",
    "# also needs numb of sentences inputs thats calculated in background "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(6), Dimension(1024)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape\n",
    "# [batch_size, max_length, 512]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with seq len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-a90fc7d0fda8>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-a90fc7d0fda8>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    signature = \"default\",\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sentence_embedding_with_seq_len = elmo( \n",
    "                                    inputs = { #6                           # 7                          #8\n",
    "                                    [\"the cat is on the mat \", \"dogs are in the fog extra text\",\" long sent be I am hungry want food\"],\n",
    "                                    \"sequence_len\"  : 8                                         \n",
    "                                    },\n",
    "                                    signature = \"default\",\n",
    "                                    as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 . Passing tokenized sentences as ip\n",
    "**signature=\"tokens\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "tokens_input = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"],\n",
    "                [\"dogs\", \"are\", \"in\", \"the\", \"fog\", \"\"]]\n",
    "# also needs numb of sentences inputs thats calculated in background\n",
    "tokens_length = [6, 5]\n",
    "\n",
    "token_embeddings = elmo(inputs={\n",
    "                            \"tokens\": tokens_input,\n",
    "                            \"sequence_len\": tokens_length\n",
    "                          },\n",
    "                  signature=\"tokens\",\n",
    "                  as_dict=True)[\"elmo\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(6), Dimension(1024)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape\n",
    "# batch size , token_max , lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embedding (seq_len , 1024) \n",
    "* 1024 hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(6), Dimension(1024)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(UniversalEmbedding, output_shape=(512, ))(input_text)\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "pred = Dense(2, activation='softmax')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using [elmo] test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "test1 = elmo([\"the cat is on the mat \"],\n",
    "                  signature=\"default\",\n",
    "                  as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(6), Dimension(1024)])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024,)\n",
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "print(test1[0][2].shape) #CAT\n",
    "print(test1[0][5].shape) # MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1[0][2] == test1[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using [default]\n",
    "**default: a fixed mean-pooling of all contextualized word representations with shape [batch_size, 1024].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "test2 = elmo([\"the cat is on the mat \"],\n",
    "                  signature=\"default\",\n",
    "                  as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(1024)])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.shape  # has sent embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with multiple sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(1024)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = elmo([\"the cat is on the mat \", \"dogs are in the fog\",\"I am hungry want food\"],\n",
    "                  signature=\"default\",\n",
    "                  as_dict=True)[\"default\"]\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using [\"word_emb\"]\n",
    "**the character-based word representations with shape [batch_size, max_length, 512].**\n",
    "* char level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "test3_ = elmo([\"the cat is on the mat \"],\n",
    "                  signature=\"default\",\n",
    "                  as_dict=True)[\"word_emb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(6), Dimension(512)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(6, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(test3_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## as per me\n",
    "Below shape=(1, 1, 16, 32) (1, 2, 16, 32) , (1, 3, 16, 64) , (1, 4, 16, 128) , (1, 5, 16, 256) ,  shape=(1, 6, 16, 512) , shape=(1, 7, 16, 1024)\n",
    "\n",
    "* (w, x, y, z)\n",
    "* (w ,x ) is size of kernel to perform char level convolution\n",
    "* (y) is max sequence of word\n",
    "* (z) is number of filter\n",
    "\n",
    "* 2048 number of hidden state of biLM model\n",
    "* finally connected to 512 Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'module_1/aggregation/scaling:0' shape=() dtype=float32>,\n",
       " <tf.Variable 'module_1/aggregation/weights:0' shape=(3,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/W_cnn_0:0' shape=(1, 1, 16, 32) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/W_cnn_1:0' shape=(1, 2, 16, 32) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/W_cnn_2:0' shape=(1, 3, 16, 64) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/W_cnn_3:0' shape=(1, 4, 16, 128) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/W_cnn_4:0' shape=(1, 5, 16, 256) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/W_cnn_5:0' shape=(1, 6, 16, 512) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/W_cnn_6:0' shape=(1, 7, 16, 1024) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/b_cnn_0:0' shape=(32,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/b_cnn_1:0' shape=(32,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/b_cnn_2:0' shape=(64,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/b_cnn_3:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/b_cnn_4:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/b_cnn_5:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN/b_cnn_6:0' shape=(1024,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_high_0/W_carry:0' shape=(2048, 2048) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_high_0/W_transform:0' shape=(2048, 2048) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_high_0/b_carry:0' shape=(2048,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_high_0/b_transform:0' shape=(2048,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_high_1/W_carry:0' shape=(2048, 2048) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_high_1/W_transform:0' shape=(2048, 2048) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_high_1/b_carry:0' shape=(2048,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_high_1/b_transform:0' shape=(2048,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_proj/W_proj:0' shape=(2048, 512) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/CNN_proj/b_proj:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0' shape=(16384,) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0' shape=(1024, 16384) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'module_1/bilm/char_embed:0' shape=(261, 16) dtype=float32>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "a = ['aaa bbbb cccc uuuu vvvv wrwr', 'ddd ee fffff ppppp']\n",
    "a = np.array(a, dtype=object)[:, np.newaxis]\n",
    "a.shape==(2,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
